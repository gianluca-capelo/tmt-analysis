{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T14:24:28.283440Z",
     "start_time": "2025-09-19T14:24:27.939172Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/gianluca/Research/tmt-analysis/results/classification/2025-09-12_1559/group/demographic+digital/folds.csv\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:25:10.920150Z",
     "start_time": "2025-09-19T14:25:10.906819Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "da76dbfaf191dca8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   model  fold  y_test  y_pred  y_pred_proba  \\\n",
       "0    SVC     0       0       1      0.638511   \n",
       "1    SVC     1       1       0      0.270154   \n",
       "2    SVC     2       1       1      0.799857   \n",
       "3    SVC     3       0       1      0.376258   \n",
       "4    SVC     4       1       0      0.500000   \n",
       "..   ...   ...     ...     ...           ...   \n",
       "69   SVC    69       1       1      0.564343   \n",
       "70   SVC    70       1       1      0.782687   \n",
       "71   SVC    71       1       1      0.241393   \n",
       "72   SVC    72       0       1      0.654494   \n",
       "73   SVC    73       0       1      0.232964   \n",
       "\n",
       "                                        feature_names  \\\n",
       "0   ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "1   ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "2   ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "3   ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "4   ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "..                                                ...   \n",
       "69  ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "70  ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "71  ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "72  ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "73  ['area_difference_from_ideal_PART_A', 'area_di...   \n",
       "\n",
       "                                      hyperparameters  \\\n",
       "0   {'C': 0.1, 'break_ties': False, 'cache_size': ...   \n",
       "1   {'C': 1, 'break_ties': False, 'cache_size': 20...   \n",
       "2   {'C': 1, 'break_ties': False, 'cache_size': 20...   \n",
       "3   {'C': 0.1, 'break_ties': False, 'cache_size': ...   \n",
       "4   {'C': 1, 'break_ties': False, 'cache_size': 20...   \n",
       "..                                                ...   \n",
       "69  {'C': 0.1, 'break_ties': False, 'cache_size': ...   \n",
       "70  {'C': 1, 'break_ties': False, 'cache_size': 20...   \n",
       "71  {'C': 0.1, 'break_ties': False, 'cache_size': ...   \n",
       "72  {'C': 1, 'break_ties': False, 'cache_size': 20...   \n",
       "73  {'C': 0.1, 'break_ties': False, 'cache_size': ...   \n",
       "\n",
       "                               select_k_best_features  \n",
       "0   ['average_duration_PART_B', 'distance_differen...  \n",
       "1   ['average_duration_PART_B', 'distance_differen...  \n",
       "2   ['average_duration_PART_B', 'distance_differen...  \n",
       "3   ['average_duration_PART_B', 'distance_differen...  \n",
       "4   ['average_duration_PART_B', 'distance_differen...  \n",
       "..                                                ...  \n",
       "69  ['average_duration_PART_B', 'distance_differen...  \n",
       "70  ['average_duration_PART_B', 'distance_differen...  \n",
       "71  ['average_duration_PART_B', 'distance_differen...  \n",
       "72  ['average_duration_PART_B', 'distance_differen...  \n",
       "73  ['average_duration_PART_B', 'distance_differen...  \n",
       "\n",
       "[74 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>select_k_best_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638511</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 0.1, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799857</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376258</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 0.1, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SVC</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564343</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 0.1, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>SVC</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782687</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>SVC</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.241393</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 0.1, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SVC</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654494</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SVC</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>['area_difference_from_ideal_PART_A', 'area_di...</td>\n",
       "      <td>{'C': 0.1, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>['average_duration_PART_B', 'distance_differen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:25:28.395352Z",
     "start_time": "2025-09-19T14:25:28.390551Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"fold\"]",
   "id": "87a6269adcca8460",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "      ..\n",
       "69    69\n",
       "70    70\n",
       "71    71\n",
       "72    72\n",
       "73    73\n",
       "Name: fold, Length: 74, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:26:41.564308Z",
     "start_time": "2025-09-19T14:26:41.559882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#get row with fold 0\n",
    "df[df[\"fold\"] == 1][\"model\"].values[0]"
   ],
   "id": "71b815a3d8ad5b57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVC'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:52:19.300742Z",
     "start_time": "2025-09-19T15:52:19.243726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "import shap\n",
    "\n",
    "from src.config import MAX_SELECTED_FEATURES\n",
    "from src.model.run_models import retrieve_dataset, get_models\n",
    "\n",
    "\n",
    "def _fresh_estimator(models, model_name):\n",
    "    for m in models:\n",
    "        if m.__class__.__name__ == model_name:\n",
    "            return m.__class__(**m.get_params())\n",
    "    raise ValueError(f\"Estimator '{model_name}' not found in model zoo.\")\n",
    "\n",
    "def _build_pipeline_no_pca(model, is_classification, feature_selection, X_train_shape, select_score_func):\n",
    "    step_name = 'classifier' if is_classification else 'regressor'\n",
    "    select_step = (\n",
    "        ('select', SelectKBest(score_func=select_score_func, k=min(MAX_SELECTED_FEATURES, X_train_shape[1])))\n",
    "        if feature_selection else ('select_noop', 'passthrough')\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        select_step,\n",
    "        ('scaler', StandardScaler()),\n",
    "        (step_name, model),\n",
    "    ])\n",
    "    return pipe, step_name\n",
    "\n",
    "#TODO GIAN: Ver si pasar esto a shap\n",
    "# def _callable_for_shap(fitted_pipeline, is_classification, positive_class_index=1):\n",
    "#     if is_classification:\n",
    "#         if hasattr(fitted_pipeline, \"predict_proba\"):\n",
    "#             return lambda X: fitted_pipeline.predict_proba(X)[:, positive_class_index]\n",
    "#         elif hasattr(fitted_pipeline, \"decision_function\"):\n",
    "#             return lambda X: fitted_pipeline.decision_function(X)\n",
    "#         else:\n",
    "#             return lambda X: fitted_pipeline.predict(X)  # last resort\n",
    "#     else:\n",
    "#         return lambda X: fitted_pipeline.predict(X)\n",
    "\n",
    "def parse_hparams(s):\n",
    "    if isinstance(s, dict):\n",
    "        return s\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return {}\n",
    "    s = s.strip()\n",
    "    # 1) JSON\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 2) Python literal (maneja comillas simples, None, True/False)\n",
    "    try:\n",
    "        d = ast.literal_eval(s)\n",
    "        return d if isinstance(d, dict) else {}\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 3) fallback simple\n",
    "    s2 = (s.replace(\"'\", '\"')\n",
    "            .replace(\" None\", \" null\").replace(\": None\", \": null\")\n",
    "            .replace(\" True\", \" true\").replace(\": True\", \": true\")\n",
    "            .replace(\" False\", \" false\").replace(\": False\", \": false\"))\n",
    "    return json.loads(s2)\n",
    "\n",
    "\n",
    "def shap_after_nested_cv(\n",
    "    dataset_name: str,\n",
    "    target_col,\n",
    "    is_classification: bool,\n",
    "    feature_selection: bool,\n",
    "    global_seed: int,\n",
    "    model_name_to_explain: str,\n",
    "    folds_csv_path: str,\n",
    "    positive_class_index: int = 1,\n",
    "    background_cap: int = 100,\n",
    "    # If you stored indices originally, pass them here to guarantee identical folds:\n",
    "    stored_indices_csv: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Refit per outer LOO fold with stored hyperparameters (no PCA),\n",
    "    compute SHAP for that fold's test sample(s), and return:\n",
    "      shap_values_df: DataFrame [samples x features]\n",
    "      mean_abs_shap: Series (mean |SHAP| per feature)\n",
    "    \"\"\"\n",
    "    X, y, feature_names = retrieve_dataset(dataset_name, target_col, is_classification)\n",
    "    feature_names = np.array(feature_names)\n",
    "    models = get_models(global_seed, is_classification)\n",
    "\n",
    "    folds_df = pd.read_csv(folds_csv_path)\n",
    "    folds_df = folds_df[folds_df['model'] == model_name_to_explain].copy()\n",
    "    if folds_df.empty:\n",
    "        raise ValueError(f\"No rows for model '{model_name_to_explain}' in {folds_csv_path}\")\n",
    "\n",
    "    # Parse hyperparameters (stringified dict → dict)\n",
    "    if folds_df['hyperparameters'].dtype == object:\n",
    "        folds_df['hyperparameters'] = folds_df['hyperparameters'].apply(\n",
    "            lambda s: parse_hparams(s)\n",
    "        )\n",
    "    folds_df = folds_df.sort_values('fold').reset_index(drop=True)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    fold_splits = list(loo.split(X, y))\n",
    "    if len(fold_splits) != len(folds_df):\n",
    "        raise RuntimeError(\"Current LOO fold count and folds.csv rows differ. \"\n",
    "                           \"Persist and reuse train/test indices to guarantee identity.\")\n",
    "\n",
    "    select_score_func = f_classif if is_classification else f_regression\n",
    "\n",
    "    rows = []\n",
    "    row_index = []\n",
    "    for fold_id, ((train_idx, test_idx), fold_row) in enumerate(zip(fold_splits, folds_df.itertuples(index=False))):\n",
    "        if fold_id != fold_row.fold:\n",
    "            raise RuntimeError(f\"Fold order mismatch at fold {fold_id} vs {fold_row.fold}.\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "\n",
    "        est = _fresh_estimator(models, model_name_to_explain)\n",
    "        pipe, step_name = _build_pipeline_no_pca(\n",
    "            est, is_classification, feature_selection, X_train.shape, select_score_func\n",
    "        )\n",
    "        # Apply per-fold estimator params\n",
    "        final_est = pipe.named_steps[step_name]\n",
    "        final_est.set_params(**fold_row.hyperparameters)\n",
    "        pipe.named_steps[step_name] = final_est\n",
    "\n",
    "        # Fit on training portion of this fold\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        # Model-agnostic explainer on original features\n",
    "        #TODO GIAN: ver si usar background\n",
    "\n",
    "        # # Map names after SelectKBest\n",
    "        # if feature_selection and 'select' in pipe.named_steps:\n",
    "        #     support_idx = pipe.named_steps['select'].get_support(indices=True)\n",
    "        #     shap_feature_names = np.asarray(feature_names)[support_idx]\n",
    "        #     print(f\"Fold {fold_id}: selected {len(shap_feature_names)}/{len(feature_names)} features for SHAP.\")\n",
    "        #     print(f\"Selected features: {shap_feature_names}\")\n",
    "        # else:\n",
    "        #     shap_feature_names = np.asarray(feature_names)\n",
    "\n",
    "        explainer = shap.Explainer(pipe, feature_names=feature_names)\n",
    "\n",
    "        # Explain the test sample(s)\n",
    "        expl = explainer(X_test)  # Explanation\n",
    "        vals = np.array(expl.values).reshape(len(X_test), len(feature_names))\n",
    "\n",
    "        rows.append(vals)\n",
    "        # index = (fold_id, each test sample index)\n",
    "        ti = test_idx if isinstance(test_idx, (list, np.ndarray)) else np.array([test_idx])\n",
    "        row_index.extend([(fold_id, int(i)) for i in ti])\n",
    "\n",
    "    # Assemble per-sample SHAP\n",
    "    shap_values = np.vstack(rows) if len(rows) else np.empty((0, len(feature_names)))\n",
    "    shap_values_df = pd.DataFrame(shap_values, columns=feature_names)\n",
    "    shap_values_df.index = pd.MultiIndex.from_tuples(row_index, names=[\"fold\", \"test_idx\"])\n",
    "\n",
    "    # Aggregate: mean absolute SHAP per feature\n",
    "    mean_abs_shap = shap_values_df.abs().mean(axis=0).sort_values(ascending=False)\n",
    "\n",
    "    return shap_values_df, mean_abs_shap"
   ],
   "id": "40713f5e26957e07",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:52:22.890165Z",
     "start_time": "2025-09-19T15:52:22.791110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.config import MODEL_OUTER_SEED\n",
    "\n",
    "shap_after_nested_cv(\n",
    "    dataset_name=\"demographic+digital\",\n",
    "    target_col=\"group\",\n",
    "    is_classification=True,\n",
    "    feature_selection=True,\n",
    "    global_seed=MODEL_OUTER_SEED,\n",
    "    model_name_to_explain=\"SVC\",\n",
    "    folds_csv_path=\"/home/gianluca/Research/tmt-analysis/results/classification/2025-09-12_1559/group/demographic+digital/folds.csv\",\n",
    ")"
   ],
   "id": "1fdfec8f7b7381fa",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The passed model is not callable and cannot be analyzed directly with the given masker! Model: Pipeline(steps=[('imputer', SimpleImputer()), ('select', SelectKBest(k=20)),\n                ('scaler', StandardScaler()),\n                ('classifier', SVC(C=0.1, probability=True, random_state=47))])",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MODEL_OUTER_SEED\n\u001B[0;32m----> 3\u001B[0m \u001B[43mshap_after_nested_cv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdemographic+digital\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgroup\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_classification\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mglobal_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_OUTER_SEED\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name_to_explain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSVC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfolds_csv_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/home/gianluca/Research/tmt-analysis/results/classification/2025-09-12_1559/group/demographic+digital/folds.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 148\u001B[0m, in \u001B[0;36mshap_after_nested_cv\u001B[0;34m(dataset_name, target_col, is_classification, feature_selection, global_seed, model_name_to_explain, folds_csv_path, positive_class_index, background_cap, stored_indices_csv)\u001B[0m\n\u001B[1;32m    134\u001B[0m pipe\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Model-agnostic explainer on original features\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;66;03m#TODO GIAN: ver si usar background\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;66;03m# else:\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m#     shap_feature_names = np.asarray(feature_names)\u001B[39;00m\n\u001B[0;32m--> 148\u001B[0m explainer \u001B[38;5;241m=\u001B[39m \u001B[43mshap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExplainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;66;03m# Explain the test sample(s)\u001B[39;00m\n\u001B[1;32m    151\u001B[0m expl \u001B[38;5;241m=\u001B[39m explainer(X_test)  \u001B[38;5;66;03m# Explanation\u001B[39;00m\n",
      "File \u001B[0;32m~/Research/tmt-analysis/venv/lib/python3.10/site-packages/shap/explainers/_explainer.py:206\u001B[0m, in \u001B[0;36mExplainer.__init__\u001B[0;34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m             algorithm \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpermutation\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;66;03m# if we get here then we don't know how to handle what was given to us\u001B[39;00m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 206\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    207\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe passed model is not callable and cannot be analyzed directly with the given masker! Model: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    208\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(model)\n\u001B[1;32m    209\u001B[0m         )\n\u001B[1;32m    211\u001B[0m \u001B[38;5;66;03m# build the right subclass\u001B[39;00m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m algorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexact\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mTypeError\u001B[0m: The passed model is not callable and cannot be analyzed directly with the given masker! Model: Pipeline(steps=[('imputer', SimpleImputer()), ('select', SelectKBest(k=20)),\n                ('scaler', StandardScaler()),\n                ('classifier', SVC(C=0.1, probability=True, random_state=47))])"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
